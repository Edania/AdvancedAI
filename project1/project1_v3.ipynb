{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e0a29-68e3-426b-9274-6020398be8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import invgamma\n",
    "import scipy.integrate as integrate\n",
    "import scipy.optimize as opt\n",
    "import emcee\n",
    "import corner\n",
    "import matplotlib\n",
    "font = {'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edcdb4-de8a-4a21-9057-bab281879664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the supernova (cosmological) redshift data\n",
    "datafile = open('SCPUnion2.1_mu_vs_z.txt','r')\n",
    "SCP_data = pd.read_table(datafile,comment='#',\n",
    "                        names=['SN name','Redshift','Distance modulus',\n",
    "                                   'Distance modulus error','P low mass'])\n",
    "print(SCP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3463a4-35d5-4662-9d43-a0a1b46fa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SCPUnion2.1_mu_vs_z.txt'\n",
    "\n",
    "# Load the data from the file\n",
    "data = np.loadtxt(filename, usecols=(1, 2, 3, 4), skiprows = 5)\n",
    "Nd = 580\n",
    "c = 299792.458 # km/s\n",
    "alpha = 0.121851859725\n",
    "beta = 2.46569277393\n",
    "\n",
    "z = data[:, 0] # size: 580x1\n",
    "mu = data[:, 1]\n",
    "mu_error = data[:, 2]\n",
    "P_low_mass = data[:, 3]\n",
    "dl = 10**(mu/5-5)\n",
    "dl_error = 10**(mu/5-5)*(10**(mu_error/5) - 1)\n",
    "\n",
    "low = z < 0.5\n",
    "\n",
    "low_z = z[low] # size: 412x1\n",
    "low_mu = mu[low]\n",
    "low_mu_error = mu_error[low]\n",
    "low_P_low_mass = P_low_mass[low]\n",
    "low_dl = 10**(low_mu/5-5)\n",
    "low_dl_error = dl_error[low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bfa02-5fee-454d-996d-1731c4dd7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.errorbar(low_z, low_mu, yerr=low_mu_error, fmt='o', ecolor='gray', linestyle='None', markersize=4)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('mu')\n",
    "plt.title('low mu')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.errorbar(low_z, low_dl, yerr=low_dl_error, fmt='o', ecolor='gray', linestyle='None', markersize=4)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('dl')\n",
    "plt.title('low dl')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d257c8-4bdb-48c4-8ce5-dbfb3e232478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52a4ad-ab69-4278-8512-0921fa22176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized weights.\n",
    "W = np.square(1/low_dl_error)\n",
    "Nw = np.sum(W)/412\n",
    "W = W/Nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347453a-2dd5-4bc2-8f11-11f1756142c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_model(z, H0, q0):\n",
    "    return c / H0 * (z + 0.5 * (1-q0) * z**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222883d-00c4-4c2f-839b-cf48fa9ad9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(param, z, dl, W):\n",
    "    H0, q0, sig2 = param\n",
    "    n = len(dl)\n",
    "    return -0.5 * (np.sum((dl - dl_model(z, H0, q0))**2 * W / sig2)) - (n/2) * np.log(2 * np.pi * sig2)\n",
    "\n",
    "def log_prior(sig2):\n",
    "    if sig2 > 1e-16:\n",
    "        return invgamma.logpdf(sig2, a = alpha, scale = beta) \n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "def log_posterior(param, z, dl, W):\n",
    "    lp = log_prior(param[-1])\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    ll = log_likelihood(param, z, dl, W)\n",
    "    return ll + lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3f859-42df-4370-ab22-92e821045605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mcmc_analysis(sampler, pars, labels, burn_in, title):\n",
    "\n",
    "    print(f'Mean acceptance fraction: {np.mean(sampler.acceptance_fraction):0.3f}')\n",
    "    # discard the first 'burn_in' samples \n",
    "    \n",
    "    # thinning means that you only keep every nth sample. E.g. thinning=10 -> keep every 10th sample.\n",
    "    # This can be useful for reducing long autocorrelation lenghts in a chain. However, thinning is expensive.\n",
    "    # A thinned chain must be run E.g. 10x longer to reach the desired number of samples.\n",
    "    # One can argue that thinning is not an advantageous strategy. So keep thinning = 1\n",
    "    thinning = 1\n",
    "    flat_mcmc_samples = sampler.get_chain(discard=burn_in,thin=thinning, flat=True)\n",
    "    print(f'Discarding {nwalkers*burn_in} steps as burn-in')\n",
    "    print(f'Chain length:{len(flat_mcmc_samples)}')\n",
    "    fig1 = plt.figure();\n",
    "    for par in pars:\n",
    "        mean = np.sum(flat_mcmc_samples[:5000,par]) / len(flat_mcmc_samples[:5000,par])\n",
    "        sub_mean = flat_mcmc_samples[:5000,par]-mean \n",
    "        if max(sub_mean) > abs(min(sub_mean)):\n",
    "            plt.plot(sub_mean/(2*max(sub_mean)),alpha=0.5, label = labels[par])\n",
    "        else: \n",
    "            plt.plot(sub_mean/(-2*min(sub_mean)),alpha=0.5, label = labels[par])\n",
    "    plt.xlabel('Sample');\n",
    "    plt.ylabel(\"Normalized parameter value\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    #plt.xlim(0,len(flat_mcmc_samples));\n",
    "    #plt.savefig(f\"{label}_trace.png\")\n",
    "    return flat_mcmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661c4f7-6d45-48ed-9b8a-7bf2bcbfba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers = 3, 50\n",
    "start_pos = [70, -0.4, 200] + 1 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "sampler_1 = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=(low_z, low_dl, W))\n",
    "sampler_1.run_mcmc(start_pos, 10000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb221bce-798b-46da-b249-567bc5141282",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_mcmc_samples = simple_mcmc_analysis(sampler_1, [0,1,2], labels=[f'$H_0$ [km/s/mPc]', f\"$q_0$\", f\"$\\sigma^2$\"], burn_in=60,title = f\"Traces of all parameters, shifted and norm., before burn-in\")\n",
    "#flat_mcmc_samples = simple_mcmc_analysis(sampler, par=1, label=f'$q_0$', burn_in=60)\n",
    "#flat_mcmc_samples = simple_mcmc_analysis(sampler, par=2, label=f'$\\sigma^2$', burn_in=60)\n",
    "\n",
    "fig = corner.corner(flat_mcmc_samples,labels=[r\"$H_0$\", r\"$q_0$\", r\"$\\sigma^2$\"],show_titles=True, bins=20)\n",
    "#plt.savefig('corner_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find autocorrelation function\n",
    "tau = np.arange(0,1000)\n",
    "samples_1 = sampler_1.chain[:, 3000:, :]\n",
    "n_samples = len(samples_1[0,:,0])\n",
    "def auto_corr(samples):\n",
    "    mean = np.sum(samples)/n_samples\n",
    "    vector = samples - mean\n",
    "    c_hat = np.empty(len(tau)+1)\n",
    "    for t in tau:\n",
    "        if t == 0:\n",
    "            c_hat[t] = np.sum(vector[:]*vector[:])/(n_samples)    \n",
    "        #print((vector[:-t]*vector[t:]).shape)\n",
    "        #if t != 100:\n",
    "        #print(vector[:-t].shape)\n",
    "        #print(vector[t:].shape)\n",
    "        else:\n",
    "            c_hat[t] = np.sum(vector[:-t]*vector[t:])/(n_samples-t)\n",
    "    return c_hat[:-1]\n",
    "auto_corr_H0 = auto_corr(samples_1[0,:,0])\n",
    "auto_corr_q0 = auto_corr(samples_1[0,:,1])\n",
    "auto_corr_sigma = auto_corr(samples_1[0,:,2])\n",
    "\n",
    "for w in range(1,nwalkers):\n",
    "    auto_corr_H0 += auto_corr(samples_1[w,:,0])\n",
    "    auto_corr_q0 += auto_corr(samples_1[w,:,1])\n",
    "    auto_corr_sigma += auto_corr(samples_1[w,:,2])\n",
    "\n",
    "tau_plot = tau\n",
    "plt.figure()\n",
    "plt.plot(tau_plot, auto_corr_H0/max(auto_corr_H0), label = f\"$H_0$\")\n",
    "plt.plot(tau_plot, auto_corr_q0/max(auto_corr_q0), label = f\"$q_0$\")\n",
    "plt.plot(tau_plot, auto_corr_sigma/max(auto_corr_sigma), label = f\"$\\sigma^2$\")\n",
    "plt.xlim(0,100)\n",
    "plt.xlabel(r\"$\\tau$\")\n",
    "plt.ylabel(r\"$\\rho(\\tau)$\")\n",
    "plt.legend()\n",
    "plt.title(\"Auto-correlation function for each parameter (after burn-in)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ef4cc-03a3-48db-8e06-3eb022e45174",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_values = np.linspace(0, 0.5, 500)\n",
    "#z_cherry = low_z[low_dl < 3500]\n",
    "#dl_cherry = low_dl[low_dl < 3500]\n",
    "\n",
    "samples = flat_mcmc_samples[:, :2]\n",
    "\n",
    "# Calculate dl_model values for each sample\n",
    "dl_samples = np.array([dl_model(z_values, *params) for params in samples])\n",
    "\n",
    "# Calculate percentiles for the credible interval\n",
    "lower_bound = np.percentile(dl_samples, 5, axis=0)\n",
    "upper_bound = np.percentile(dl_samples, 95, axis=0)\n",
    "median_dl = np.median(dl_samples, axis=0)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(3, figsize = (7,7))\n",
    "plt.scatter(low_z, low_dl, s=10, alpha=0.4, label='Data')\n",
    "plt.plot(z_values, median_dl, color='black',label='Model median')\n",
    "plt.fill_between(z_values, lower_bound, upper_bound, color='gray', alpha=0.5, label='90% Credible Interval')\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$d_L$ [Mpc]')\n",
    "plt.legend()\n",
    "plt.title(\"Predicted model curve against SCP 2.1 data\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('PPD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e31936-0861-4f54-91c2-0f01aa61b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check av H0. För z > 0.075 är anpassningen sämre. Endast en term i utvecklingen av dl är här medtagen.\n",
    "\n",
    "# Medelvärden.\n",
    "H0_mean, q0_mean, sig2_mean = np.array([np.mean(flat_mcmc_samples[:,k]) for k in range(0,len(flat_mcmc_samples[0]))])\n",
    "lower_z = low_z[low_z < 0.075]\n",
    "lower_dl = low_dl[low_z < 0.075]\n",
    "lower_dl_error = low_dl_error[low_z < 0.075]\n",
    "z_lower_lin = np.linspace(0, 0.075, 500)\n",
    "\n",
    "plt.figure(4, figsize=(7,7))\n",
    "#plt.scatter(lower_z, lower_dl, s=10)\n",
    "plt.errorbar(lower_z, lower_dl, yerr = lower_dl_error, barsabove=True, fmt='.', alpha = 0.5)\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$d_L [Mpc]$')\n",
    "plt.plot(z_lower_lin, z_lower_lin*c/H0_mean, color='black')\n",
    "plt.title(r\"Linear model for low $z$ using extracted mean of $H_0$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"linear_PPD.png\")\n",
    "\n",
    "print(f\"H_0: {H0_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26078645-d6c1-4655-bd96-7d0532e02391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57b9ac-0737-4d4f-b742-b81405883167",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(z)\n",
    "sorted_z = z[sorted_indices]\n",
    "sorted_dl = dl[sorted_indices]\n",
    "\n",
    "c = 299792.458\n",
    "H0 = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf5aab-9a41-47b9-848b-824b8e660c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCDM and wCDM models.\n",
    "def E_wCDM(z, Omega_M0, w):\n",
    "    return Omega_M0*(1+z)**3 + (1-Omega_M0)*(1+z)**(3*(1+w))\n",
    "\n",
    "def E_LCDM(z, Omega_M0, w):\n",
    "    return Omega_M0*(1+z)**3 + (1-Omega_M0)\n",
    "\n",
    "# Eq 15.\n",
    "def dl_model_full(E, z, Omega_M, w=None):\n",
    "    dl_values = np.zeros_like(z)\n",
    "    for i, z_i in enumerate(z):\n",
    "        integral, _ = integrate.quad(lambda z: 1 / np.sqrt(E(z, Omega_M, w)), 0, z_i)\n",
    "        dl_values[i] = c * (1 + z_i) / H0 * integral\n",
    "\n",
    "    return dl_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fe7ea-e4a8-4faf-9365-1c53911fd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, model, z, dl, dl_error):\n",
    "    if model == 'LCDM':\n",
    "        Omega_M0 = params[0]\n",
    "        model = dl_model_full(E_LCDM, z, Omega_M0)\n",
    "    elif model == 'wCDM':\n",
    "        Omega_M0, w = params\n",
    "        model = dl_model_full(E_wCDM, z, Omega_M0, w)\n",
    "\n",
    "    w = 1 / dl_error**2\n",
    "    w = len(dl_error)*w/sum(w)\n",
    "    n = len(dl)\n",
    "    return -0.5 * np.sum((dl - model) ** 2 * w) #+ (n/2)*np.log(2*np.pi*np.sum(dl_error**2))\n",
    "\n",
    "neg_log_likelihood = lambda *args: -log_likelihood(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ad38e-b181-4436-9591-c7c293331120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimum ΛCDM Model\n",
    "initial_guess_LCDM = [0.3]  # Initial guess for Omega_M\n",
    "result_LCDM = opt.minimize(neg_log_likelihood, initial_guess_LCDM, args=('LCDM', z, dl, dl_error))\n",
    "\n",
    "# Optimum wCDM Model\n",
    "initial_guess_wCDM = [0.3, -1]  # Initial guesses for Omega_M and w\n",
    "result_wCDM = opt.minimize(neg_log_likelihood, initial_guess_wCDM, args=('wCDM', z, dl, dl_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13663408-dabb-4690-a820-9ca76772345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIC and AIC scores. Minus the def. in the lecture notes.\n",
    "aic_lcdm = -(2 * len(initial_guess_LCDM) + 2 * (-result_LCDM.fun))\n",
    "bic_lcdm = -(len(initial_guess_LCDM) * np.log(len(z)) + 2 * (-result_LCDM.fun))\n",
    "\n",
    "aic_wcdm = -(2 * len(initial_guess_wCDM) + 2 * (-result_wCDM.fun))\n",
    "bic_wcdm = -(len(initial_guess_wCDM) * np.log(len(z)) + 2 * (-result_wCDM.fun))\n",
    "\n",
    "diff_aic = aic_lcdm-aic_wcdm\n",
    "diff_bic = bic_lcdm-bic_wcdm\n",
    "diff_omega = result_LCDM.x - result_wCDM.x[0]\n",
    "# Results\n",
    "print(f\"AIC for ΛCDM: {aic_lcdm}, BIC for ΛCDM: {bic_lcdm}\")\n",
    "print(f\"AIC for wCDM: {aic_wcdm}, BIC for wCDM: {bic_wcdm}\")\n",
    "print(f\"Diff AIC = {diff_aic}, Diff BIC = {diff_bic}\")\n",
    "print(f\"Omega_M0 from ΛCDM: {result_LCDM.x}\")\n",
    "print(f\"Omega_M0 and w from wCDM: {result_wCDM.x}\")\n",
    "print(f\"Difference in Omega_M0: {diff_omega}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11231c3-1ba5-44ea-827e-3e7549e847c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(Omega_M0):\n",
    "    if 0.0 <= Omega_M0 <= 1.0:\n",
    "        return 0.0 \n",
    "    return -np.inf\n",
    "\n",
    "def log_posterior(Omega_M0, z, dl, dl_error):\n",
    "    prior = log_prior(Omega_M0)\n",
    "    if not np.isfinite(prior):\n",
    "        return -np.inf\n",
    "    return prior + log_likelihood(Omega_M0, 'LCDM', z, dl, dl_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad7c26-03cb-4f24-9406-ff6405a532cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC of Omega_M0 of LCDM. Long runtime. Adjust nwalker and nsteps as you like.\n",
    "\n",
    "ndim = 1\n",
    "nwalkers = 20\n",
    "burn_in = 1000\n",
    "initial = np.random.rand(nwalkers, ndim)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=(z, dl, dl_error))\n",
    "\n",
    "nsteps = 2000\n",
    "sampler.run_mcmc(initial, nsteps, progress=True)\n",
    "\n",
    "samples = sampler.chain[:, burn_in:, :].reshape((-1, ndim))  # Discard first 200 steps as burn-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 1\n",
    "nwalkers = 20\n",
    "burn_in = 1000\n",
    "\n",
    "samples = sampler.chain[:, burn_in:, :].reshape((-1, ndim))  # Discard first 200 steps as burn-in\n",
    "\n",
    "flat_mcmc_samples = simple_mcmc_analysis(sampler, [0], labels=['$\\Omega_{M,0}$'], burn_in=0, title = \"Trace of $\\Omega_{M,0}$ before burn-in\")\n",
    "#Find autocorrelation function\n",
    "tau = np.arange(0,1000)\n",
    "walker_samples = sampler.chain[:,burn_in:,:]\n",
    "n_samples = len(walker_samples[0,:,0])\n",
    "auto_corr_omega = auto_corr(walker_samples[0,:,0])\n",
    "for w in range(1,nwalkers):\n",
    "    auto_corr_omega += auto_corr(walker_samples[w,:,0])\n",
    "\n",
    "tau_plot = tau\n",
    "plt.figure()\n",
    "plt.plot(tau_plot, auto_corr_omega/max(auto_corr_omega), label = \"$\\Omega_{M,0}$\")\n",
    "plt.xlim(0,100)\n",
    "plt.xlabel(r\"$\\tau$\")\n",
    "plt.ylabel(r\"$\\rho(\\tau)$\")\n",
    "plt.legend()\n",
    "plt.title(\"Auto-correlation function for $\\Omega_{M,0}$ (after burn-in)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4592b8-7caa-4017-8b76-fbf967d138f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Omega_M0 = np.mean(samples[:, 0])\n",
    "median_Omega_M0 = np.median(samples[:, 0])\n",
    "std_omega = np.std(samples[:,0])\n",
    "print(std_omega)\n",
    "#lower_bound = np.percentile(samples[:,0], 25, axis=0)\n",
    "#upper_bound = np.percentile(samples[:,0], 95, axis=0)\n",
    "\n",
    "hist, bins = np.histogram(samples[:, 0], bins='auto', density=True)\n",
    "bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "# Find the mode\n",
    "mode_index = np.argmax(hist)\n",
    "mode_value = bin_centers[mode_index]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Plotting.\n",
    "plt.hist(samples[:, 0], density = True,bins=bins, alpha=0.8)\n",
    "plt.xlabel('$\\Omega_{M0}$')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior Distribution of $\\Omega_{M0}$')\n",
    "plt.axvline(mean_Omega_M0, color='red', linewidth=2, label=f'Mean: {mean_Omega_M0:.4f} $\\pm$ {std_omega:.4f}')\n",
    "plt.axvline(mean_Omega_M0+std_omega, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.axvline(mean_Omega_M0-std_omega, color='red', linestyle='dashed', linewidth=2)\n",
    "\n",
    "#plt.axvline(median_Omega_M0, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median_Omega_M0:.4f}')\n",
    "#plt.axvline(mode_value, color='yellow', linestyle='dashed', linewidth=2, label=f'Mode: {mode_value:.4f}')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Omega_M0_Distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Print the mean value\n",
    "print(f\"Mean Omega_M0: {mean_Omega_M0}\")\n",
    "corner.corner(samples,bins=20, show_titles=True, labels= [\"$\\Omega_{M,0}$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
